{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOAN1iZATlTN"
   },
   "source": [
    "## Pre-requisite: Library requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "sKs-idswBdWG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (1.21.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: six in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement glob (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for glob\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for os\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (0.0.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # !nvidia-smi\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install glob\n",
    "%pip install os \n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "_d_VCjDnBgSy"
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m0_Cluster_Rivers.jpeg\u001b[0m/                   \u001b[01;32m8523-Ying.ipynb\u001b[0m*\n",
      "\u001b[01;32m8523_Common.ipynb\u001b[0m*                       8523_Ying_UCL_Experiments.ipynb\n",
      "8523_data_processing_70.ipynb            8523_Ying_UCL_Experiments-Task1.ipynb\n",
      "8523_data_processing_80.ipynb            \u001b[01;32mcore.3755254\u001b[0m*\n",
      "8523_data_processing_90.ipynb            \u001b[01;32mcore.3779393\u001b[0m*\n",
      "8523_data_processing_kmeans_taks1.ipynb  \u001b[01;32mcore.3780321\u001b[0m*\n",
      "\u001b[01;32m8523_Shonal2.ipynb\u001b[0m*                      \u001b[01;32mexplanation.jpg\u001b[0m*\n",
      "\u001b[01;32m8523-Shonal.ipynb\u001b[0m*                       model_training_history.png\n",
      "\u001b[01;32m8523-Tanisha.ipynb\u001b[0m*                      \u001b[01;32mREADME.md\u001b[0m*\n",
      "\u001b[01;32m8523_Task2_RTL_Exp_100_317.ipynb\u001b[0m*        \u001b[01;32mShonal3.ipynb\u001b[0m*\n",
      "8523_Task2_RTL_Exp_70_2726.ipynb         \u001b[01;32mShonal4.ipynb\u001b[0m*\n",
      "8523_Task2_RTL_Exp_90_1940.ipynb         \u001b[01;32mShonal5.ipynb\u001b[0m*\n",
      "8523_Task2_UCL_Exp_100_317.ipynb         \u001b[01;32mShonal6_visualization.ipynb\u001b[0m*\n",
      "8523_Task2_UCL_Exp_70_2726.ipynb         Shonal7_fixing80.ipynb\n",
      "8523_Task2_UCL_Exp_90_1940.ipynb         \u001b[01;32msplit_dataset.ipynb\u001b[0m*\n",
      "\u001b[01;32m8523_Task2_UCL_Pipeline_Testing.ipynb\u001b[0m*   TODO For Task 2\n",
      "8523_Task2_Visualization.ipynb           \u001b[01;32mvisualize.py\u001b[0m*\n",
      "8523_UCL-Ying.ipynb                      Ying_UCL_Task1_visualization.ipynb\n",
      "\u001b[0m\u001b[01;34mfrac_map\u001b[0m/                              \u001b[01;34mshonal_test\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold70\u001b[0m/      \u001b[01;34mshonal_unlabeled\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold80\u001b[0m/      \u001b[01;34mtest\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold80_new\u001b[0m/  \u001b[01;34mtime_series\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold90\u001b[0m/      \u001b[01;34mtrain\u001b[0m/\n",
      "\u001b[01;34mshonal\u001b[0m/                                \u001b[01;34mUCL_Results\u001b[0m/\n",
      "\u001b[01;34mshonal1\u001b[0m/                               \u001b[01;34mUCL_Results_Ying\u001b[0m/\n",
      "\u001b[01;34mshonal2\u001b[0m/                               \u001b[01;34mUCL_Results_Ying_Task1\u001b[0m/\n",
      "\u001b[01;34mshonal3\u001b[0m/                               \u001b[01;34mying_labeled_test\u001b[0m/\n",
      "\u001b[01;34mshonal4\u001b[0m/                               \u001b[01;34mying_unlabeled_train\u001b[0m/\n",
      "\u001b[01;34mshonal5\u001b[0m/\n",
      "\u001b[0m\u001b[01;32mID_000083_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000103_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000172_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000208_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000271_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000287_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000288_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000298_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000299_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000303_frac_map.npy\u001b[0m*\n",
      "ls: write error\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "%ls ../data\n",
    "%ls ../data/frac_map | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_maps len is  26754 total_ts len is  26754\n",
      "(1, 64, 64)\n",
      "(442, 1)\n"
     ]
    }
   ],
   "source": [
    "fracmaps_dir = '../data/frac_map'\n",
    "frac_maps = os.listdir(fracmaps_dir)\n",
    "timeseries_dir = '../data/time_series'\n",
    "time_series = os.listdir(timeseries_dir)\n",
    "\n",
    "total_maps = len(frac_maps) # 26754\n",
    "total_ts = len(time_series) # 26754\n",
    "print(\"total_maps len is \", total_maps, \"total_ts len is \", total_ts)\n",
    "\n",
    "## save fraction map and time series into img arrays\n",
    "for i in range(0, total_maps):\n",
    "    fm = frac_maps[i]\n",
    "    frac_maps[i] = np.load(os.path.join(fracmaps_dir, fm), allow_pickle=True)\n",
    "    ts = time_series[i]\n",
    "    time_series[i] = np.load(os.path.join(timeseries_dir, ts), allow_pickle=True)\n",
    "    \n",
    "\n",
    "print(frac_maps[0].shape) ## (1,64,64)\n",
    "print(time_series[0].shape) ## (442, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ID_742140_frac_map.npy'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = os.listdir('../data/frac_map')\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "ID_labels = '../label_info/all_IDs_labels.npy'\n",
    "ID_labels = np.load(ID_labels, allow_pickle=True)\n",
    "\n",
    "# size of all labels\n",
    "print(ID_labels.shape) ## (1000000,)\n",
    "\n",
    "# check size of each label\n",
    "# print(np.where(ID_labels==0)[0].shape) # (979799,) - unknown\n",
    "# print(np.where(ID_labels==1)[0].shape) # (427,) - farm\n",
    "# print(np.where(ID_labels==2)[0].shape) # (18707,) - reservoir\n",
    "# print(np.where(ID_labels==3)[0].shape) # (317,) - river\n",
    "# print(np.where(ID_labels==4)[0].shape) # (143,) - stable lakes\n",
    "# print(np.where(ID_labels==5)[0].shape) # (288,) - seasonal lakes\n",
    "# print(np.where(ID_labels==6)[0].shape) # (52,) - highly seasonal lakes\n",
    "# print(np.where(ID_labels==7)[0].shape) # (255) - ephemeral lakes\n",
    "# print(np.where(ID_labels==8)[0].shape) # (12,) - river runoff/oxbow\n",
    "\n",
    "# fm_river_labels = np.where(ID_labels==3)[0]\n",
    "# fm_river_labels\n",
    "# print(fm_river_labels)\n",
    "# fname = '../data/frac_map/ID_409869_frac_map.npy'\n",
    "# s = np.load(fname, allow_pickle=True)\n",
    "# river_0 = np.squeeze(s, axis = 0)\n",
    "# plt.imshow(river_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Save all river fraction maps in the fm_rivers and river time series in the ts_rivers array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317,)\n",
      "(317, 1, 64, 64)\n",
      "(317, 442, 1)\n"
     ]
    }
   ],
   "source": [
    "# extract river from fraction maps and time series maps\n",
    "river_ids = np.where(ID_labels==3)[0]\n",
    "print(river_ids.shape) # 317\n",
    "#fracmaps_dir = '../data/frac_map'\n",
    "#timeseries_dir = '../data/time_series'\n",
    "fm_rivers = []\n",
    "ts_rivers = []\n",
    "pre = 'ID_'\n",
    "fm_post = '_frac_map.npy'\n",
    "ts_post = '_time_series.npy'\n",
    "\n",
    "for sid in river_ids:\n",
    "    fm_name = pre + str(sid) + fm_post\n",
    "    ts_name = pre + str(sid) + ts_post\n",
    "    fm_path = os.path.join(fracmaps_dir, fm_name)\n",
    "    ts_path = os.path.join(timeseries_dir, ts_name)\n",
    "    fm_rivers.append(np.load(fm_path, allow_pickle=True))\n",
    "    ts_rivers.append(np.load(ts_path, allow_pickle=True))\n",
    "#     print(np.load(ts_path, allow_pickle=True).shape) # (442,1)\n",
    "\n",
    "fm_rivers = np.array(fm_rivers)\n",
    "ts_rivers = np.array(ts_rivers)\n",
    "print(fm_rivers.shape) # should be 317\n",
    "print(ts_rivers.shape) # should be 317\n",
    "\n",
    "# visualize the first river fraction map\n",
    "# river_0 = np.squeeze(fm_rivers[0], axis = 0)\n",
    "# plt.imshow(river_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgozhBCqRDxW"
   },
   "source": [
    "# Preprocessing frac_maps\n",
    "\n",
    "Currently, we have 26754 fraction maps. Each of these is of shape 1x64x64. Let's change that to 64x64 and aggregate them all into one array where each value is tuple in the form (name of file, 64x64 array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "nZ9bQq63PP45"
   },
   "outputs": [],
   "source": [
    "fms = [] # fraction map: contains each 26754 64*64 array\n",
    "\n",
    "for i in range(0, len(frac_maps)):\n",
    "    fms.append(frac_maps[i][0])\n",
    "    \n",
    "fms = np.array(fms)\n",
    "# print(fms[0])\n",
    "# plt.imshow(fms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import cv2\n",
    "from kmeanstf import KMeansTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_742140_frac_map.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_filename = os.listdir('../data/frac_map') # has a 1-1 mapping with fms => fm_filename[i] is the filename of fms[i]\n",
    "print(fm_filename[0])\n",
    "ID_labels[0] # ID_labels is the ground truth array, len = 100,0000, ID_labels[ID] = class_no, ID is from filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x_train is fms[i] which is a 64*64 2d array, y_train is ID_labels[getID(fm_filename, i)] which is a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741138"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a helper function which gets the ID of a fraction map array given the idx\n",
    "\n",
    "def getID(fm_fn, idx):\n",
    "    fn = fm_fn[idx] # get the file name\n",
    "    fm_id = int(re.findall(r'\\d+', fn)[0])\n",
    "    return fm_id\n",
    "\n",
    "getID(fm_filename, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26754\n",
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "for i in range(0, len(fms)):\n",
    "    y_train.append(ID_labels[getID(fm_filename, i)])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "print(len(y_train))\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24682,)\n",
      "(427,)\n",
      "(578,)\n",
      "(317,)\n",
      "(143,)\n",
      "(288,)\n",
      "(52,)\n",
      "(255,)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "## check y_train label distribution \n",
    "print(np.where(y_train==0)[0].shape)\n",
    "print(np.where(y_train==1)[0].shape)\n",
    "print(np.where(y_train==2)[0].shape)\n",
    "print(np.where(y_train==3)[0].shape)\n",
    "print(np.where(y_train==4)[0].shape)\n",
    "print(np.where(y_train==5)[0].shape)\n",
    "print(np.where(y_train==6)[0].shape)\n",
    "print(np.where(y_train==7)[0].shape)\n",
    "print(np.where(y_train==8)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data is already between 0 to 1 we do not require normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26754, 64, 64)\n",
      "(26754,)\n",
      "(64, 64)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(fms.shape)\n",
    "print(y_train.shape)\n",
    "print(fms[0].shape)\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26754, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping input data\n",
    "X_train = fms.reshape(len(fms),-1)\n",
    "#X_test = x_test.reshape(len(x_test),-1)\n",
    "print(X_train.shape)\n",
    "# training, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is (26754, 4096). (64 x 64 = 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.random.shuffle(fms)\n",
    "# training, test = fms[:80,:], dictionary[80:,:]\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(fms, y_train, test_size=0.2, random_state=42)\n",
    "# print(X_train[0].shape) # 64*64\n",
    "# print(X_train.shape) # 64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26754\n",
      "(2072, 64, 64)\n",
      "2072\n",
      "(24682, 64, 64)\n",
      "(317, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "labeled = [] # has labels 1,2,3,4,5,6,7,8\n",
    "y_labeled = [] # corresponding label\n",
    "unlabeled = [] # anything else (24682, )\n",
    "x_river = [] # holding rivers 317\n",
    "\n",
    "print(len(fms)) # 26754 , 0 - 8\n",
    "\n",
    "for i in range(0, len(fms)):\n",
    "\n",
    "    label = ID_labels[getID(fm_filename, i)]\n",
    "    \n",
    "    if (label == 3):\n",
    "        x_river.append(fms[i])\n",
    "\n",
    "    if (label == 0): # unknown \n",
    "        unlabeled.append(fms[i])\n",
    "    else:\n",
    "        labeled.append(fms[i])\n",
    "        y_labeled.append(label)\n",
    "      \n",
    "    \n",
    "labeled = np.array(labeled)\n",
    "unlabeled = np.array(unlabeled)\n",
    "x_river = np.array(x_river)\n",
    "print(labeled.shape)\n",
    "print(len(y_labeled))\n",
    "print(unlabeled.shape)\n",
    "print(x_river.shape)\n",
    "\n",
    "\n",
    "# # save into data/ying_unlabeled_train folder\n",
    "# for i in range(0, len(unlabeled)):\n",
    "#     img_name = \"../data/ying_unlabeled_train/\" + str(i) + \".jpeg\"\n",
    "#     matplotlib.image.imsave(img_name, unlabeled[i])\n",
    "\n",
    "    \n",
    "# # save into data/ying_labeled_test folder\n",
    "# for i in range(0, len(labeled)):\n",
    "#     img_name = \"../data/ying_labeled_test/\" + str(i) + \".jpeg\"\n",
    "#     matplotlib.image.imsave(img_name, labeled[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training dataset: unlabeled\n",
    "### river test dataset: x_river\n",
    "\n",
    "# Reshape input dataset as required by resnet50v2\n",
    "from skimage.transform import resize\n",
    "im = np.reshape(unlabeled,(24682,64,64,1))\n",
    "im = resize(im, (24682,64,64,3))\n",
    "im.shape\n",
    "X_train = im\n",
    "\n",
    "\n",
    "# Reshape input dataset as required by resnet50v2\n",
    "im = np.reshape(x_river,(317,64,64,1))\n",
    "im = resize(im, (317,64,64,3))\n",
    "im.shape\n",
    "X_test = im\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we use unlabeled to fit into the ucl model and train the mode, then fit into the x_river to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some helper function \n",
    "def visualize(data, data_size, cols, title, fx, fy, dtype='graph'):\n",
    "    if data_size > 0:\n",
    "        rows = (data_size//cols) + 1\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(fx,fy))\n",
    "        fig.suptitle(title,y=1.0,fontsize=40,ha='center')\n",
    "        ax = axes.ravel()\n",
    "        for i in range(0, data_size):\n",
    "            if dtype == 'image':\n",
    "                ax[i].imshow(data[i])\n",
    "            else:\n",
    "                ax[i].plot(data[i])\n",
    "\n",
    "        for a in ax:\n",
    "                a.set_axis_off()\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files(data,folder,image):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    for i in range(0, len(data)):\n",
    "        img_name = folder + str(i) + \".jpeg\"\n",
    "        image.imsave(img_name, data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(num_cluster = 1):\n",
    "    # Extract features of remote sensing imagery of water bodies and \n",
    "    # non-water bodies using a pre-trained deep learning architecture.\n",
    "    resnet = ResNet50V2(include_top=False, pooling='avg', weights='imagenet',input_shape = (64,64,3))#, classes = 3)\n",
    "\n",
    "    # ResNet model doesn't contain the flattened fully connected layers, so we add them separately.\n",
    "    resnet.layers\n",
    "\n",
    "    # ResNet model doesn't contain the flattened fully connected layers, so we add them separately.\n",
    "    # print(resnet.summary()[-8])\n",
    "#     print(resnet.layers[-1].output)\n",
    "\n",
    "    # ResNet model doesn't contain the flattened fully connected layers, so we add them separately.\n",
    "    ucl_model = Sequential()\n",
    "    ucl_model.add(resnet)\n",
    "    ucl_model.add(Flatten())\n",
    "    ucl_model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    ucl_model.add(Dense(1, activation='softmax'))\n",
    "      \n",
    "    # freeze resnet50 conv layers and keep only new layers for fine-tuning. \n",
    "    ucl_model.layers[0].trainable = False\n",
    "#     print(ucl_model.summary())\n",
    "    return {'ucl_model':ucl_model}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as matplotlib_image\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Lambda, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.models import Model\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedCurriculumLearning():\n",
    "    \n",
    "    def __init__(self, ucl_model, plt, clusters, selection_threshold, train_epochs, x_train):\n",
    "        self.ucl_model = ucl_model\n",
    "        self.clusters = clusters\n",
    "        self.selection_threshold = selection_threshold\n",
    "        self.train_epochs = train_epochs   \n",
    "        self.x_train = x_train\n",
    "\n",
    "    def step1(self):\n",
    "        # run pretrained model once at the beginning\n",
    "        ucl_classes = self.ucl_model.predict(self.x_train)\n",
    "        # classification results for binary classification of rivers, using imagenet weights\n",
    "        print(\"Classes predicted by UCL Model for the first 10 rivers are : \", str(ucl_classes[:10]))\n",
    "        return {'predicted_classes':ucl_classes}\n",
    "\n",
    "    def step2(self, plt):\n",
    "        # Step 2:\n",
    "        # Create two clusters on the extracted features of remote sensing imagery, assigning \n",
    "        # them pseudo-labels of 'static rivers' and 'may meander rivers'\n",
    "\n",
    "        # Kmeans\n",
    "        # The images are classified into clusters based on similarity of pixel values. \n",
    "        # Each image is assigned a cluster label value given by kmeans.labels_. \n",
    "        # So kmeans.labels_ is an array of length 26754 as there are 26754 images in the training set.\n",
    "        # The input to kmeans comes from the following layer which have imagenet weights after step 1.\n",
    "\n",
    "        print(\"Layer type: \", self.ucl_model.layers[-3])\n",
    "        print(\"Layer details: \",self.ucl_model.layers[-3].output)\n",
    "\n",
    "        # create a new model to extract the features from ucl_model. This is the actual input to kmeans.\n",
    "        # extracted features from the resnet50v2 layer - ucl_model.layers[-3]\n",
    "        model_features= Model(inputs=self.ucl_model.inputs, outputs=self.ucl_model.layers[-3].output)\n",
    "        features = model_features.predict(self.x_train)  \n",
    "#         print(features.shape) # should be (len(x_train), 2048)\n",
    "\n",
    "        # visualize first 10 images, 3 cols\n",
    "#         visualize(features, 10, 3, 'Feature Visualization', *(20,20))\n",
    "\n",
    "        # Initialize the class object\n",
    "        kmeans = KMeans(n_clusters=self.clusters)\n",
    "\n",
    "        # Fit kmeans to the labels of clusters.\n",
    "        kmeans = kmeans.fit(features)\n",
    "\n",
    "#         print(\"All Kmeans labels for x_train: \", kmeans.labels_)\n",
    "#         print(\"Kmeans cluster centers: \", kmeans.cluster_centers_)\n",
    "\n",
    "        # filter rows of original data\n",
    "        tot_clusters = self.clusters\n",
    "        for i in range(0,tot_clusters) : \n",
    "            print(\"Total number of rivers in cluster\", i, \": \",features[kmeans.labels_==i].shape) \n",
    "            name = 'Features in Cluster '+str(i)\n",
    "            # only visualize first 10 rivers in each cluster \n",
    "#             visualize(features[kmeans.labels_==i][:10], 10, 3, name, *(20,20))   \n",
    "\n",
    "        return {'cluster_centers':kmeans.cluster_centers_,'features':features,'kmeans_labels':kmeans.labels_}\n",
    "\n",
    "    def step3(self, centers, features, kmeans_labels):\n",
    "        # Step 3 : \n",
    "        # From each cluster, select the reliable images using the UCL based selection operation. \n",
    "        # Select all features that are at a distance 位 from the centroid of the cluster. \n",
    "        # The parameter 位 is a constant value \n",
    "        # that can be adjusted according to the requirement. We have used 位 = 0.85 after empirical evaluations.  \n",
    "        # The closest feature vector to the centroid is considered as a centroid feature vector. \n",
    "        # We calculate the similarity between a specific feature vector fi belonging to a cluster k \n",
    "        # and the centroid feature vector fk using the inner product. \n",
    "        # If the calculated similarity is greater than the 位, the sample of the considered feature vector \n",
    "        # is declared as a reliable sample and the cluster label is considered as the pseudo sample label \n",
    "        # for the next training cycle.  \n",
    "        # The number of extracted reliable samples vary at every iteration of fine tuning. \n",
    "\n",
    "        # calculate cosine similarity \n",
    "\n",
    "        feature_centers = []\n",
    "        tot_clusters = self.clusters\n",
    "        \n",
    "        for cluster in range(0,tot_clusters):\n",
    "            label_i = features[kmeans_labels == cluster]\n",
    "            dot_product = np.dot(centers[cluster],label_i.T) #(1,2048).(2048,len(labels0))\n",
    "            normalize_product = norm(centers[cluster])*norm(label_i,axis=1)\n",
    "            center_i = dot_product/normalize_product\n",
    "#             print(\"Similarity to centroid \",cluster ,\":  \",center_i[0:3])\n",
    "            feature_centers.append(center_i)\n",
    "\n",
    "        # printing the size of all clusters after selecting using threshold.\n",
    "        for cluster in range(0, tot_clusters):\n",
    "            # get selected features\n",
    "            training_class_i = center_i[center_i >= self.selection_threshold]\n",
    "#             print(\"Total features selected for centroid \",cluster,\": \",training_class_i.shape)\n",
    "\n",
    "        # Below is probably the most complicated cell in this entire notebook.\n",
    "        x_train = []\n",
    "        y_label = []\n",
    "\n",
    "        for center in range(0, tot_clusters):        \n",
    "            # get the indices of the feature maps from first center, selected using the threshold . \n",
    "            selected_class_index = np.asarray(np.where(feature_centers[center] >= self.selection_threshold))[0,:]\n",
    "            # get the indices of the images belonging to the first center\n",
    "            label_index = np.asarray(np.where(kmeans_labels == center))[0,:]\n",
    "\n",
    "#             print(\"Indices belonging to cluster \",center,\": \",label_index)\n",
    "#             print(\"Indices selected for fine-tuning: \", selected_class_index)\n",
    "#             print(\"Indices of the images to be sent to model: \", label_index[selected_class_index])\n",
    "\n",
    "            # get the selected rivers\n",
    "            rivers = self.x_train[list(label_index[selected_class_index])] \n",
    "            title = \"Selected Rivers in cluster \" + str(center)\n",
    "            x_train = x_train + list(rivers)\n",
    "            y_label = y_label + [center]*len(rivers)\n",
    "            \n",
    "            # visualize all rivers in current cluster, 4 cols, \n",
    "#             visualize(rivers[:,:,:,1], rivers.shape[0], 4, title, 20, 70, 'image')\n",
    "#             visualize(rivers[:,:,:,1], 6, 6, title, 20, 70, 'image') # visualize 10 images\n",
    "           \n",
    "        # Create the dataset\n",
    "        x_train = np.array(x_train)\n",
    "        y_label = np.array(y_label)\n",
    "        print(f'After selection, there are {len(x_train)} selected from {len(self.x_train)}')\n",
    "        \n",
    "        return {'x_train':x_train,'y_label':y_label}\n",
    "\n",
    "    def step4(self, x_train, y_label):\n",
    "        # Step 4 : \n",
    "        # Fine-tune the deep learning module on reliable samples using pseudo labels given by the clusters. \n",
    "        print('in step4, x_train is ', x_train.shape)\n",
    "        print('in step4, y_label is ', np.array(y_label).shape)\n",
    "        train = ImageDataGenerator()\n",
    "        training = train.flow(x_train,y_label,batch_size = 100)\n",
    "        print(\"The training data with selected images and predicted label from kmeans is \", training)\n",
    "        \n",
    "        self.ucl_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "       \n",
    "        history = (self.ucl_model).fit(training, epochs = self.train_epochs, steps_per_epoch=len(training))\n",
    "        \n",
    "        # plot the loss history\n",
    "        \n",
    "        return self.ucl_model\n",
    "    \n",
    "    def run_ucl(self, plt) :\n",
    "        kmeans_results = self.step2(plt)\n",
    "        centers = kmeans_results['cluster_centers']\n",
    "        features = kmeans_results['features']\n",
    "        kmeans_labels = kmeans_results['kmeans_labels']\n",
    "        selected_images = self.step3(centers, features, kmeans_labels)\n",
    "        \n",
    "        # update ucl_model by updating weights of the new added layers\n",
    "        self.ucl_model = self.step4(selected_images['x_train'], selected_images['y_label'])\n",
    "        \n",
    "        return {'model':self.ucl_model, 'x_train':selected_images['x_train'],'y_label':selected_images['y_label'], 'centers': centers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/UCL_Results_Ying_Task1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to run experiment\n",
    "def run_exp(experiment, num_clusters, model, threshold, max_iter, Xtrain, max_training_epoches):\n",
    "    print(f\"######### in {experiment} results #########\")\n",
    "    exp = UnsupervisedCurriculumLearning(model, plt, num_clusters, threshold, max_training_epoches, Xtrain)\n",
    "    # although we focus on the last epoch's result, save all results as well to see if there any difference by training\n",
    "#     prev_centers = []\n",
    "#     centers = []\n",
    "#     clusters = []\n",
    "#     for i in range(0, max_iter):\n",
    "#         print(f'starting iteration {i} \\n')\n",
    "#         data = exp.run_ucl(plt)\n",
    "#         rivers = data['x_train']\n",
    "#         clusters = data['y_label']\n",
    "#         prev_centers = centers\n",
    "#         centers = data['centers']\n",
    "\n",
    "    # converge when centers converge, or when iterations hit 10.\n",
    "    past_center = np.array([np.array([0]*2048)]*2)\n",
    "    curr_center = np.array([np.array([1]*2048)]*2)\n",
    "    iterations = 0\n",
    "    while((curr_center == past_center).all() or iterations < max_iter):\n",
    "        past_center = curr_center\n",
    "        data = exp.run_ucl(plt)\n",
    "        curr_center = data['centers']\n",
    "        iterations = iterations + 1\n",
    "        print(\"Iteration is: \",iterations)\n",
    "        print('\\n\\n\\n')\n",
    "        \n",
    "    rivers = data['x_train']\n",
    "    clusters = data['y_label']\n",
    "\n",
    "    clusters = np.array(clusters)\n",
    "    for cluster in range(0,len(np.unique(clusters))):\n",
    "        results = folder_path + experiment + \"/cluster_\"+str(cluster)+\"/\"\n",
    "        save_files(rivers[np.where(clusters == cluster)[0]], results, matplotlib_image)\n",
    "        \n",
    "        \n",
    "    # save model\n",
    "    path = results + 'model'\n",
    "    data['model'].save(path)\n",
    "    # read model\n",
    "    mode = model.load_model(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_training_epoches = 10 # for model.fit() function\n",
    "max_iter = 10 # for training, alternative is to check centroid for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### in EXP0_thresh80 results #########\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f12bff6bcd0>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "772/772 [==============================] - 306s 397ms/step\n",
      "Total number of rivers in cluster 0 :  (11278, 2048)\n",
      "Total number of rivers in cluster 1 :  (13404, 2048)\n",
      "After selection, there are 8777 selected from 24682\n",
      "in step4, x_train is  (8777, 64, 64, 3)\n",
      "in step4, y_label is  (8777,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f12cce064d0>\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 109s 1s/step - loss: 0.0905 - accuracy: 0.0967\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 80s 909ms/step - loss: 0.0179 - accuracy: 0.0967\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 149s 2s/step - loss: 0.0126 - accuracy: 0.0967\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 76s 865ms/step - loss: 0.0096 - accuracy: 0.0967\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 82s 924ms/step - loss: 0.0076 - accuracy: 0.0967\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 79s 901ms/step - loss: 0.0062 - accuracy: 0.0967\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 75s 855ms/step - loss: 0.0044 - accuracy: 0.0967\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 127s 1s/step - loss: 0.0038 - accuracy: 0.0967\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 123s 1s/step - loss: 0.0027 - accuracy: 0.0967\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 114s 1s/step - loss: 0.0024 - accuracy: 0.0967\n",
      "Iteration is:  1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f12bff6bcd0>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "772/772 [==============================] - 267s 343ms/step\n",
      "Total number of rivers in cluster 0 :  (11278, 2048)\n",
      "Total number of rivers in cluster 1 :  (13404, 2048)\n",
      "After selection, there are 8777 selected from 24682\n",
      "in step4, x_train is  (8777, 64, 64, 3)\n",
      "in step4, y_label is  (8777,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f12413e87d0>\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 100s 1s/step - loss: 0.0038 - accuracy: 0.0967\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 98s 1s/step - loss: 0.0026 - accuracy: 0.0967\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 71s 805ms/step - loss: 0.0039 - accuracy: 0.0967\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 84s 951ms/step - loss: 0.0010 - accuracy: 0.0967\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 71s 808ms/step - loss: 0.0015 - accuracy: 0.0967\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 71s 806ms/step - loss: 7.7663e-04 - accuracy: 0.0967\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 72s 813ms/step - loss: 6.2600e-04 - accuracy: 0.0967\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 73s 826ms/step - loss: 2.8461e-04 - accuracy: 0.0967\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 61s 688ms/step - loss: 2.1482e-04 - accuracy: 0.0967\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 67s 761ms/step - loss: 2.1286e-04 - accuracy: 0.0967\n",
      "Iteration is:  2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f12bff6bcd0>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "772/772 [==============================] - 261s 338ms/step\n",
      "Total number of rivers in cluster 0 :  (11279, 2048)\n",
      "Total number of rivers in cluster 1 :  (13403, 2048)\n",
      "After selection, there are 8777 selected from 24682\n",
      "in step4, x_train is  (8777, 64, 64, 3)\n",
      "in step4, y_label is  (8777,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f12a775edd0>\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 131s 1s/step - loss: 0.0022 - accuracy: 0.0966\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 114s 1s/step - loss: 7.9933e-04 - accuracy: 0.0966\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 78s 892ms/step - loss: 0.0026 - accuracy: 0.0966\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 72s 813ms/step - loss: 0.0017 - accuracy: 0.0966\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 142s 2s/step - loss: 0.0023 - accuracy: 0.0966\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 88s 994ms/step - loss: 7.1130e-04 - accuracy: 0.0966\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 93s 1s/step - loss: 1.3294e-04 - accuracy: 0.0966\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 142s 2s/step - loss: 7.8117e-05 - accuracy: 0.0966\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 144s 2s/step - loss: 7.1585e-05 - accuracy: 0.0966\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 137s 2s/step - loss: 5.5256e-05 - accuracy: 0.0966\n",
      "Iteration is:  3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f12bff6bcd0>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "772/772 [==============================] - 266s 344ms/step\n",
      "Total number of rivers in cluster 0 :  (13404, 2048)\n",
      "Total number of rivers in cluster 1 :  (11278, 2048)\n",
      "After selection, there are 8777 selected from 24682\n",
      "in step4, x_train is  (8777, 64, 64, 3)\n",
      "in step4, y_label is  (8777,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f123de80350>\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 107s 1s/step - loss: 6.0488 - accuracy: 0.9033\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 146s 2s/step - loss: 0.0610 - accuracy: 0.9033\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 117s 1s/step - loss: 0.0302 - accuracy: 0.9033\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 108s 1s/step - loss: 0.0225 - accuracy: 0.9033\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 95s 1s/step - loss: 0.0184 - accuracy: 0.9033\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 115s 1s/step - loss: 0.0157 - accuracy: 0.9033\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 123s 1s/step - loss: 0.0134 - accuracy: 0.9033\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 79s 894ms/step - loss: 0.0116 - accuracy: 0.9033\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 86s 973ms/step - loss: 0.0107 - accuracy: 0.9033\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 108s 1s/step - loss: 0.0090 - accuracy: 0.9033\n",
      "Iteration is:  4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f12bff6bcd0>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "772/772 [==============================] - 221s 286ms/step\n",
      "Total number of rivers in cluster 0 :  (11278, 2048)\n",
      "Total number of rivers in cluster 1 :  (13404, 2048)\n",
      "After selection, there are 8777 selected from 24682\n",
      "in step4, x_train is  (8777, 64, 64, 3)\n",
      "in step4, y_label is  (8777,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f123fa22f50>\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 64s 702ms/step - loss: 1.8083 - accuracy: 0.0967\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 58s 663ms/step - loss: 0.0029 - accuracy: 0.0967\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 61s 694ms/step - loss: 0.0020 - accuracy: 0.0967\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 69s 778ms/step - loss: 0.0017 - accuracy: 0.0967\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 61s 696ms/step - loss: 0.0015 - accuracy: 0.0967\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 35s 400ms/step - loss: 0.0013 - accuracy: 0.0967\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 63s 721ms/step - loss: 0.0011 - accuracy: 0.0967\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 57s 645ms/step - loss: 0.0010 - accuracy: 0.0967\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 61s 688ms/step - loss: 9.9060e-04 - accuracy: 0.0967\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 68s 774ms/step - loss: 8.3021e-04 - accuracy: 0.0967\n",
      "Iteration is:  5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f12bff6bcd0>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
      "772/772 [==============================] - 182s 233ms/step\n",
      "Total number of rivers in cluster 0 :  (13404, 2048)\n",
      "Total number of rivers in cluster 1 :  (11278, 2048)\n",
      "After selection, there are 8777 selected from 24682\n",
      "in step4, x_train is  (8777, 64, 64, 3)\n",
      "in step4, y_label is  (8777,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f123fa11fd0>\n",
      "Epoch 1/10\n",
      "30/88 [=========>....................] - ETA: 32s - loss: 5.1044 - accuracy: 0.9057"
     ]
    }
   ],
   "source": [
    "threshold = 0.8\n",
    "ucl_model2 = select_model(1)['ucl_model']\n",
    "run_exp('EXP0_thresh80', 2, ucl_model2, threshold, max_iter, X_train, max_training_epoches)\n",
    "\n",
    "# save the model \n",
    "# torch.save(ucl_model2, 'EXP0_thresh80.pth')\n",
    "\n",
    "# load the model \n",
    "# ucl_model2 = torch.load('EXP0_thresh80.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test on the X_test dataset \n",
    "pred_classes80 = ucl_model2.predict(X_test)\n",
    "pred_classes80[pred_classes80 > 0.5] = 1\n",
    "pred_classes80[pred_classes80 <= 0.5] = 0\n",
    "# calculate accuracy / confusion matrix etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(river_labels)\n",
    "river_labels = [1] * len(pred_classes80)\n",
    "print(pred_classes80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# It counts the undefined into consideration, may need to remove those data points for computing accuracy\n",
    "print(accuracy_score(pred_classes80, river_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "MSI_Pytorch_1.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
