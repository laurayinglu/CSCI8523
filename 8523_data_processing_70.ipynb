{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOAN1iZATlTN"
   },
   "source": [
    "## Pre-requisite: Library requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sKs-idswBdWG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (1.21.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (3.5.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six in /panfs/roc/msisoft/pytorch/1.2_python3.7/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement glob (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for glob\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for os\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages (0.0.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # !nvidia-smi\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install glob\n",
    "%pip install os \n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_d_VCjDnBgSy"
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m0_Cluster_Rivers.jpeg\u001b[0m/                   \u001b[01;32m8523-Ying.ipynb\u001b[0m*\n",
      "\u001b[01;32m8523_Common.ipynb\u001b[0m*                       8523_Ying_UCL_Experiments.ipynb\n",
      "8523_data_processing_70.ipynb            8523_Ying_UCL_Experiments-Task1.ipynb\n",
      "8523_data_processing_80.ipynb            \u001b[01;32mcore.3755254\u001b[0m*\n",
      "8523_data_processing_90.ipynb            \u001b[01;32mcore.3779393\u001b[0m*\n",
      "8523_data_processing_kmeans_taks1.ipynb  \u001b[01;32mcore.3780321\u001b[0m*\n",
      "\u001b[01;32m8523_Shonal2.ipynb\u001b[0m*                      \u001b[01;32mexplanation.jpg\u001b[0m*\n",
      "\u001b[01;32m8523-Shonal.ipynb\u001b[0m*                       model_training_history.png\n",
      "\u001b[01;32m8523-Tanisha.ipynb\u001b[0m*                      \u001b[01;32mREADME.md\u001b[0m*\n",
      "\u001b[01;32m8523_Task2_RTL_Exp_100_317.ipynb\u001b[0m*        \u001b[01;32mShonal3.ipynb\u001b[0m*\n",
      "8523_Task2_RTL_Exp_70_2726.ipynb         \u001b[01;32mShonal4.ipynb\u001b[0m*\n",
      "8523_Task2_RTL_Exp_90_1940.ipynb         \u001b[01;32mShonal5.ipynb\u001b[0m*\n",
      "8523_Task2_UCL_Exp_100_317.ipynb         \u001b[01;32mShonal6_visualization.ipynb\u001b[0m*\n",
      "8523_Task2_UCL_Exp_70_2726.ipynb         Shonal7_fixing80.ipynb\n",
      "8523_Task2_UCL_Exp_90_1940.ipynb         \u001b[01;32msplit_dataset.ipynb\u001b[0m*\n",
      "\u001b[01;32m8523_Task2_UCL_Pipeline_Testing.ipynb\u001b[0m*   TODO For Task 2\n",
      "8523_Task2_Visualization.ipynb           \u001b[01;32mvisualize.py\u001b[0m*\n",
      "8523_UCL-Ying.ipynb                      Ying_UCL_Task1_visualization.ipynb\n",
      "\u001b[0m\u001b[01;34mfrac_map\u001b[0m/                              \u001b[01;34mshonal_test\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold70\u001b[0m/      \u001b[01;34mshonal_unlabeled\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold80\u001b[0m/      \u001b[01;34mtest\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold80_new\u001b[0m/  \u001b[01;34mtime_series\u001b[0m/\n",
      "\u001b[01;34mresnet50v2_predicted_threshold90\u001b[0m/      \u001b[01;34mtrain\u001b[0m/\n",
      "\u001b[01;34mshonal\u001b[0m/                                \u001b[01;34mUCL_Results\u001b[0m/\n",
      "\u001b[01;34mshonal1\u001b[0m/                               \u001b[01;34mUCL_Results_Ying\u001b[0m/\n",
      "\u001b[01;34mshonal2\u001b[0m/                               \u001b[01;34mUCL_Results_Ying_Task1\u001b[0m/\n",
      "\u001b[01;34mshonal3\u001b[0m/                               \u001b[01;34mying_labeled_test\u001b[0m/\n",
      "\u001b[01;34mshonal4\u001b[0m/                               \u001b[01;34mying_unlabeled_train\u001b[0m/\n",
      "\u001b[01;34mshonal5\u001b[0m/\n",
      "\u001b[0m\u001b[01;32mID_000083_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000103_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000172_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000208_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000271_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000287_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000288_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000298_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000299_frac_map.npy\u001b[0m*\n",
      "\u001b[01;32mID_000303_frac_map.npy\u001b[0m*\n",
      "ls: write error\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "%ls ../data\n",
    "%ls ../data/frac_map | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_maps len is  26754 total_ts len is  26754\n",
      "(1, 64, 64)\n",
      "(442, 1)\n"
     ]
    }
   ],
   "source": [
    "fracmaps_dir = '../data/frac_map'\n",
    "frac_maps = os.listdir(fracmaps_dir)\n",
    "timeseries_dir = '../data/time_series'\n",
    "time_series = os.listdir(timeseries_dir)\n",
    "\n",
    "total_maps = len(frac_maps) # 26754\n",
    "total_ts = len(time_series) # 26754\n",
    "print(\"total_maps len is \", total_maps, \"total_ts len is \", total_ts)\n",
    "\n",
    "## save fraction map and time series into img arrays\n",
    "for i in range(0, total_maps):\n",
    "    fm = frac_maps[i]\n",
    "    frac_maps[i] = np.load(os.path.join(fracmaps_dir, fm), allow_pickle=True)\n",
    "    ts = time_series[i]\n",
    "    time_series[i] = np.load(os.path.join(timeseries_dir, ts), allow_pickle=True)\n",
    "    \n",
    "\n",
    "print(frac_maps[0].shape) ## (1,64,64)\n",
    "print(time_series[0].shape) ## (442, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ID_742140_frac_map.npy'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = os.listdir('../data/frac_map')\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "ID_labels = '../label_info/all_IDs_labels.npy'\n",
    "ID_labels = np.load(ID_labels, allow_pickle=True)\n",
    "\n",
    "# size of all labels\n",
    "print(ID_labels.shape) ## (1000000,)\n",
    "\n",
    "# check size of each label\n",
    "# print(np.where(ID_labels==0)[0].shape) # (979799,) - unknown\n",
    "# print(np.where(ID_labels==1)[0].shape) # (427,) - farm\n",
    "# print(np.where(ID_labels==2)[0].shape) # (18707,) - reservoir\n",
    "# print(np.where(ID_labels==3)[0].shape) # (317,) - river\n",
    "# print(np.where(ID_labels==4)[0].shape) # (143,) - stable lakes\n",
    "# print(np.where(ID_labels==5)[0].shape) # (288,) - seasonal lakes\n",
    "# print(np.where(ID_labels==6)[0].shape) # (52,) - highly seasonal lakes\n",
    "# print(np.where(ID_labels==7)[0].shape) # (255) - ephemeral lakes\n",
    "# print(np.where(ID_labels==8)[0].shape) # (12,) - river runoff/oxbow\n",
    "\n",
    "# fm_river_labels = np.where(ID_labels==3)[0]\n",
    "# fm_river_labels\n",
    "# print(fm_river_labels)\n",
    "# fname = '../data/frac_map/ID_409869_frac_map.npy'\n",
    "# s = np.load(fname, allow_pickle=True)\n",
    "# river_0 = np.squeeze(s, axis = 0)\n",
    "# plt.imshow(river_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Save all river fraction maps in the fm_rivers and river time series in the ts_rivers array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317,)\n",
      "(317, 1, 64, 64)\n",
      "(317, 442, 1)\n"
     ]
    }
   ],
   "source": [
    "# extract river from fraction maps and time series maps\n",
    "river_ids = np.where(ID_labels==3)[0]\n",
    "print(river_ids.shape) # 317\n",
    "#fracmaps_dir = '../data/frac_map'\n",
    "#timeseries_dir = '../data/time_series'\n",
    "fm_rivers = []\n",
    "ts_rivers = []\n",
    "pre = 'ID_'\n",
    "fm_post = '_frac_map.npy'\n",
    "ts_post = '_time_series.npy'\n",
    "\n",
    "for sid in river_ids:\n",
    "    fm_name = pre + str(sid) + fm_post\n",
    "    ts_name = pre + str(sid) + ts_post\n",
    "    fm_path = os.path.join(fracmaps_dir, fm_name)\n",
    "    ts_path = os.path.join(timeseries_dir, ts_name)\n",
    "    fm_rivers.append(np.load(fm_path, allow_pickle=True))\n",
    "    ts_rivers.append(np.load(ts_path, allow_pickle=True))\n",
    "#     print(np.load(ts_path, allow_pickle=True).shape) # (442,1)\n",
    "\n",
    "fm_rivers = np.array(fm_rivers)\n",
    "ts_rivers = np.array(ts_rivers)\n",
    "print(fm_rivers.shape) # should be 317\n",
    "print(ts_rivers.shape) # should be 317\n",
    "\n",
    "# visualize the first river fraction map\n",
    "# river_0 = np.squeeze(fm_rivers[0], axis = 0)\n",
    "# plt.imshow(river_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgozhBCqRDxW"
   },
   "source": [
    "# Preprocessing frac_maps\n",
    "\n",
    "Currently, we have 26754 fraction maps. Each of these is of shape 1x64x64. Let's change that to 64x64 and aggregate them all into one array where each value is tuple in the form (name of file, 64x64 array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nZ9bQq63PP45"
   },
   "outputs": [],
   "source": [
    "fms = [] # fraction map: contains each 26754 64*64 array\n",
    "\n",
    "for i in range(0, len(frac_maps)):\n",
    "    fms.append(frac_maps[i][0])\n",
    "    \n",
    "fms = np.array(fms)\n",
    "# print(fms[0])\n",
    "# plt.imshow(fms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 18:59:07.145506: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 18:59:09.441242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages/cv2/../../lib64:/panfs/roc/msisoft/cuda/10.0/lib64\n",
      "2022-12-18 18:59:09.441267: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-18 18:59:18.026700: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages/cv2/../../lib64:/panfs/roc/msisoft/cuda/10.0/lib64\n",
      "2022-12-18 18:59:18.026885: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages/cv2/../../lib64:/panfs/roc/msisoft/cuda/10.0/lib64\n",
      "2022-12-18 18:59:18.026898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-18 18:59:31.410024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /panfs/jay/groups/6/csci8523/lu000097/.local/lib/python3.7/site-packages/cv2/../../lib64:/panfs/roc/msisoft/cuda/10.0/lib64\n",
      "2022-12-18 18:59:31.410111: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-18 18:59:31.410174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (acn01): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import cv2\n",
    "from kmeanstf import KMeansTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_742140_frac_map.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_filename = os.listdir('../data/frac_map') # has a 1-1 mapping with fms => fm_filename[i] is the filename of fms[i]\n",
    "print(fm_filename[0])\n",
    "ID_labels[0] # ID_labels is the ground truth array, len = 100,0000, ID_labels[ID] = class_no, ID is from filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x_train is fms[i] which is a 64*64 2d array, y_train is ID_labels[getID(fm_filename, i)] which is a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741138"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a helper function which gets the ID of a fraction map array given the idx\n",
    "\n",
    "def getID(fm_fn, idx):\n",
    "    fn = fm_fn[idx] # get the file name\n",
    "    fm_id = int(re.findall(r'\\d+', fn)[0])\n",
    "    return fm_id\n",
    "\n",
    "getID(fm_filename, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26754\n",
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "for i in range(0, len(fms)):\n",
    "    y_train.append(ID_labels[getID(fm_filename, i)])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "print(len(y_train))\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24682,)\n",
      "(427,)\n",
      "(578,)\n",
      "(317,)\n",
      "(143,)\n",
      "(288,)\n",
      "(52,)\n",
      "(255,)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "## check y_train label distribution \n",
    "print(np.where(y_train==0)[0].shape)\n",
    "print(np.where(y_train==1)[0].shape)\n",
    "print(np.where(y_train==2)[0].shape)\n",
    "print(np.where(y_train==3)[0].shape)\n",
    "print(np.where(y_train==4)[0].shape)\n",
    "print(np.where(y_train==5)[0].shape)\n",
    "print(np.where(y_train==6)[0].shape)\n",
    "print(np.where(y_train==7)[0].shape)\n",
    "print(np.where(y_train==8)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data is already between 0 to 1 we do not require normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26754, 64, 64)\n",
      "(26754,)\n",
      "(64, 64)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(fms.shape)\n",
    "print(y_train.shape)\n",
    "print(fms[0].shape)\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26754, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping input data\n",
    "X_train = fms.reshape(len(fms),-1)\n",
    "#X_test = x_test.reshape(len(x_test),-1)\n",
    "print(X_train.shape)\n",
    "# training, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is (26754, 4096). (64 x 64 = 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.random.shuffle(fms)\n",
    "# training, test = fms[:80,:], dictionary[80:,:]\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(fms, y_train, test_size=0.2, random_state=42)\n",
    "# print(X_train[0].shape) # 64*64\n",
    "# print(X_train.shape) # 64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26754\n",
      "(2072, 64, 64)\n",
      "2072\n",
      "(24682, 64, 64)\n",
      "(317, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "labeled = [] # has labels 1,2,3,4,5,6,7,8\n",
    "y_labeled = [] # corresponding label\n",
    "unlabeled = [] # anything else (24682, )\n",
    "x_river = [] # holding rivers 317\n",
    "\n",
    "print(len(fms)) # 26754 , 0 - 8\n",
    "\n",
    "for i in range(0, len(fms)):\n",
    "\n",
    "    label = ID_labels[getID(fm_filename, i)]\n",
    "    \n",
    "    if (label == 3):\n",
    "        x_river.append(fms[i])\n",
    "\n",
    "    if (label == 0): # unknown \n",
    "        unlabeled.append(fms[i])\n",
    "    else:\n",
    "        labeled.append(fms[i])\n",
    "        y_labeled.append(label)\n",
    "      \n",
    "    \n",
    "labeled = np.array(labeled)\n",
    "unlabeled = np.array(unlabeled)\n",
    "x_river = np.array(x_river)\n",
    "print(labeled.shape)\n",
    "print(len(y_labeled))\n",
    "print(unlabeled.shape)\n",
    "print(x_river.shape)\n",
    "\n",
    "\n",
    "# # save into data/ying_unlabeled_train folder\n",
    "# for i in range(0, len(unlabeled)):\n",
    "#     img_name = \"../data/ying_unlabeled_train/\" + str(i) + \".jpeg\"\n",
    "#     matplotlib.image.imsave(img_name, unlabeled[i])\n",
    "\n",
    "    \n",
    "# # save into data/ying_labeled_test folder\n",
    "# for i in range(0, len(labeled)):\n",
    "#     img_name = \"../data/ying_labeled_test/\" + str(i) + \".jpeg\"\n",
    "#     matplotlib.image.imsave(img_name, labeled[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training dataset: unlabeled\n",
    "### river test dataset: x_river\n",
    "\n",
    "# Reshape input dataset as required by resnet50v2\n",
    "from skimage.transform import resize\n",
    "im = np.reshape(unlabeled,(24682,64,64,1))\n",
    "im = resize(im, (24682,64,64,3))\n",
    "im.shape\n",
    "X_train = im\n",
    "\n",
    "\n",
    "# Reshape input dataset as required by resnet50v2\n",
    "im = np.reshape(x_river,(317,64,64,1))\n",
    "im = resize(im, (317,64,64,3))\n",
    "im.shape\n",
    "X_test = im\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we use unlabeled to fit into the ucl model and train the mode, then fit into the x_river to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some helper function \n",
    "def visualize(data, data_size, cols, title, fx, fy, dtype='graph'):\n",
    "    if data_size > 0:\n",
    "        rows = (data_size//cols) + 1\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(fx,fy))\n",
    "        fig.suptitle(title,y=1.0,fontsize=40,ha='center')\n",
    "        ax = axes.ravel()\n",
    "        for i in range(0, data_size):\n",
    "            if dtype == 'image':\n",
    "                ax[i].imshow(data[i])\n",
    "            else:\n",
    "                ax[i].plot(data[i])\n",
    "\n",
    "        for a in ax:\n",
    "                a.set_axis_off()\n",
    "                \n",
    "        plt.tight_layout()\n",
    "        plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files(data,folder,image):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    for i in range(0, len(data)):\n",
    "        img_name = folder + str(i) + \".jpeg\"\n",
    "        image.imsave(img_name, data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(num_cluster = 1):\n",
    "    # Extract features of remote sensing imagery of water bodies and \n",
    "    # non-water bodies using a pre-trained deep learning architecture.\n",
    "    resnet = ResNet50V2(include_top=False, pooling='avg', weights='imagenet',input_shape = (64,64,3))#, classes = 3)\n",
    "\n",
    "    # ResNet model doesn't contain the flattened fully connected layers, so we add them separately.\n",
    "    resnet.layers\n",
    "\n",
    "    # ResNet model doesn't contain the flattened fully connected layers, so we add them separately.\n",
    "    # print(resnet.summary()[-8])\n",
    "#     print(resnet.layers[-1].output)\n",
    "\n",
    "    # ResNet model doesn't contain the flattened fully connected layers, so we add them separately.\n",
    "    ucl_model = Sequential()\n",
    "    ucl_model.add(resnet)\n",
    "    ucl_model.add(Flatten())\n",
    "    ucl_model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    ucl_model.add(Dense(1, activation='softmax'))\n",
    "      \n",
    "    # freeze resnet50 conv layers and keep only new layers for fine-tuning. \n",
    "    ucl_model.layers[0].trainable = False\n",
    "#     print(ucl_model.summary())\n",
    "    return {'ucl_model':ucl_model}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as matplotlib_image\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, Lambda, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.models import Model\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedCurriculumLearning():\n",
    "    \n",
    "    def __init__(self, ucl_model, plt, clusters, selection_threshold, train_epochs, x_train):\n",
    "        self.ucl_model = ucl_model\n",
    "        self.clusters = clusters\n",
    "        self.selection_threshold = selection_threshold\n",
    "        self.train_epochs = train_epochs   \n",
    "        self.x_train = x_train\n",
    "\n",
    "    def step1(self):\n",
    "        # run pretrained model once at the beginning\n",
    "        ucl_classes = self.ucl_model.predict(self.x_train)\n",
    "        # classification results for binary classification of rivers, using imagenet weights\n",
    "        print(\"Classes predicted by UCL Model for the first 10 rivers are : \", str(ucl_classes[:10]))\n",
    "        return {'predicted_classes':ucl_classes}\n",
    "\n",
    "    def step2(self, plt):\n",
    "        # Step 2:\n",
    "        # Create two clusters on the extracted features of remote sensing imagery, assigning \n",
    "        # them pseudo-labels of 'static rivers' and 'may meander rivers'\n",
    "\n",
    "        # Kmeans\n",
    "        # The images are classified into clusters based on similarity of pixel values. \n",
    "        # Each image is assigned a cluster label value given by kmeans.labels_. \n",
    "        # So kmeans.labels_ is an array of length 26754 as there are 26754 images in the training set.\n",
    "        # The input to kmeans comes from the following layer which have imagenet weights after step 1.\n",
    "\n",
    "        print(\"Layer type: \", self.ucl_model.layers[-3])\n",
    "        print(\"Layer details: \",self.ucl_model.layers[-3].output)\n",
    "\n",
    "        # create a new model to extract the features from ucl_model. This is the actual input to kmeans.\n",
    "        # extracted features from the resnet50v2 layer - ucl_model.layers[-3]\n",
    "        model_features= Model(inputs=self.ucl_model.inputs, outputs=self.ucl_model.layers[-3].output)\n",
    "        features = model_features.predict(self.x_train)  \n",
    "#         print(features.shape) # should be (len(x_train), 2048)\n",
    "\n",
    "        # visualize first 10 images, 3 cols\n",
    "#         visualize(features, 10, 3, 'Feature Visualization', *(20,20))\n",
    "\n",
    "        # Initialize the class object\n",
    "        kmeans = KMeans(n_clusters=self.clusters)\n",
    "\n",
    "        # Fit kmeans to the labels of clusters.\n",
    "        kmeans = kmeans.fit(features)\n",
    "\n",
    "#         print(\"All Kmeans labels for x_train: \", kmeans.labels_)\n",
    "#         print(\"Kmeans cluster centers: \", kmeans.cluster_centers_)\n",
    "\n",
    "        # filter rows of original data\n",
    "        tot_clusters = self.clusters\n",
    "        for i in range(0,tot_clusters) : \n",
    "            print(\"Total number of rivers in cluster\", i, \": \",features[kmeans.labels_==i].shape) \n",
    "            name = 'Features in Cluster '+str(i)\n",
    "            # only visualize first 10 rivers in each cluster \n",
    "#             visualize(features[kmeans.labels_==i][:10], 10, 3, name, *(20,20))   \n",
    "\n",
    "        return {'cluster_centers':kmeans.cluster_centers_,'features':features,'kmeans_labels':kmeans.labels_}\n",
    "\n",
    "    def step3(self, centers, features, kmeans_labels):\n",
    "        # Step 3 : \n",
    "        # From each cluster, select the reliable images using the UCL based selection operation. \n",
    "        # Select all features that are at a distance 位 from the centroid of the cluster. \n",
    "        # The parameter 位 is a constant value \n",
    "        # that can be adjusted according to the requirement. We have used 位 = 0.85 after empirical evaluations.  \n",
    "        # The closest feature vector to the centroid is considered as a centroid feature vector. \n",
    "        # We calculate the similarity between a specific feature vector fi belonging to a cluster k \n",
    "        # and the centroid feature vector fk using the inner product. \n",
    "        # If the calculated similarity is greater than the 位, the sample of the considered feature vector \n",
    "        # is declared as a reliable sample and the cluster label is considered as the pseudo sample label \n",
    "        # for the next training cycle.  \n",
    "        # The number of extracted reliable samples vary at every iteration of fine tuning. \n",
    "\n",
    "        # calculate cosine similarity \n",
    "\n",
    "        feature_centers = []\n",
    "        tot_clusters = self.clusters\n",
    "        \n",
    "        for cluster in range(0,tot_clusters):\n",
    "            label_i = features[kmeans_labels == cluster]\n",
    "            dot_product = np.dot(centers[cluster],label_i.T) #(1,2048).(2048,len(labels0))\n",
    "            normalize_product = norm(centers[cluster])*norm(label_i,axis=1)\n",
    "            center_i = dot_product/normalize_product\n",
    "#             print(\"Similarity to centroid \",cluster ,\":  \",center_i[0:3])\n",
    "            feature_centers.append(center_i)\n",
    "\n",
    "        # printing the size of all clusters after selecting using threshold.\n",
    "        for cluster in range(0, tot_clusters):\n",
    "            # get selected features\n",
    "            training_class_i = center_i[center_i >= self.selection_threshold]\n",
    "#             print(\"Total features selected for centroid \",cluster,\": \",training_class_i.shape)\n",
    "\n",
    "        # Below is probably the most complicated cell in this entire notebook.\n",
    "        x_train = []\n",
    "        y_label = []\n",
    "\n",
    "        for center in range(0, tot_clusters):        \n",
    "            # get the indices of the feature maps from first center, selected using the threshold . \n",
    "            selected_class_index = np.asarray(np.where(feature_centers[center] >= self.selection_threshold))[0,:]\n",
    "            # get the indices of the images belonging to the first center\n",
    "            label_index = np.asarray(np.where(kmeans_labels == center))[0,:]\n",
    "\n",
    "#             print(\"Indices belonging to cluster \",center,\": \",label_index)\n",
    "#             print(\"Indices selected for fine-tuning: \", selected_class_index)\n",
    "#             print(\"Indices of the images to be sent to model: \", label_index[selected_class_index])\n",
    "\n",
    "            # get the selected rivers\n",
    "            rivers = self.x_train[list(label_index[selected_class_index])] \n",
    "            title = \"Selected Rivers in cluster \" + str(center)\n",
    "            x_train = x_train + list(rivers)\n",
    "            y_label = y_label + [center]*len(rivers)\n",
    "            \n",
    "            # visualize all rivers in current cluster, 4 cols, \n",
    "#             visualize(rivers[:,:,:,1], rivers.shape[0], 4, title, 20, 70, 'image')\n",
    "#             visualize(rivers[:,:,:,1], 6, 6, title, 20, 70, 'image') # visualize 10 images\n",
    "           \n",
    "        # Create the dataset\n",
    "        x_train = np.array(x_train)\n",
    "        y_label = np.array(y_label)\n",
    "        print(f'After selection, there are {len(x_train)} selected from {len(self.x_train)}')\n",
    "        \n",
    "        return {'x_train':x_train,'y_label':y_label}\n",
    "\n",
    "    def step4(self, x_train, y_label):\n",
    "        # Step 4 : \n",
    "        # Fine-tune the deep learning module on reliable samples using pseudo labels given by the clusters. \n",
    "        print('in step4, x_train is ', x_train.shape)\n",
    "        print('in step4, y_label is ', np.array(y_label).shape)\n",
    "        train = ImageDataGenerator()\n",
    "        training = train.flow(x_train,y_label,batch_size = 100)\n",
    "        print(\"The training data with selected images and predicted label from kmeans is \", training)\n",
    "        \n",
    "        self.ucl_model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "       \n",
    "        history = (self.ucl_model).fit(training, epochs = self.train_epochs, steps_per_epoch=len(training))\n",
    "        \n",
    "        # plot the loss history\n",
    "        \n",
    "        return self.ucl_model\n",
    "    \n",
    "    def run_ucl(self, plt) :\n",
    "        kmeans_results = self.step2(plt)\n",
    "        centers = kmeans_results['cluster_centers']\n",
    "        features = kmeans_results['features']\n",
    "        kmeans_labels = kmeans_results['kmeans_labels']\n",
    "        selected_images = self.step3(centers, features, kmeans_labels)\n",
    "        \n",
    "        # update ucl_model by updating weights of the new added layers\n",
    "        self.ucl_model = self.step4(selected_images['x_train'], selected_images['y_label'])\n",
    "        \n",
    "        return {'model':self.ucl_model, 'x_train':selected_images['x_train'],'y_label':selected_images['y_label'], 'centers': centers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/UCL_Results_Ying_Task1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to run experiment\n",
    "def run_exp(experiment, num_clusters, model, threshold, max_iter, Xtrain, max_training_epoches):\n",
    "    print(f\"######### in {experiment} results #########\")\n",
    "    exp = UnsupervisedCurriculumLearning(model, plt, num_clusters, threshold, max_training_epoches, Xtrain)\n",
    "    # although we focus on the last epoch's result, save all results as well to see if there any difference by training\n",
    "#     prev_centers = []\n",
    "#     centers = []\n",
    "#     clusters = []\n",
    "#     for i in range(0, max_iter):\n",
    "#         print(f'starting iteration {i} \\n')\n",
    "#         data = exp.run_ucl(plt)\n",
    "#         rivers = data['x_train']\n",
    "#         clusters = data['y_label']\n",
    "#         prev_centers = centers\n",
    "#         centers = data['centers']\n",
    "\n",
    "    # converge when centers converge, or when iterations hit 10.\n",
    "    past_center = np.array([np.array([0]*2048)]*2)\n",
    "    curr_center = np.array([np.array([1]*2048)]*2)\n",
    "    iterations = 0\n",
    "    while((curr_center == past_center).all() or iterations < max_iter):\n",
    "        past_center = curr_center\n",
    "        data = exp.run_ucl(plt)\n",
    "        curr_center = data['centers']\n",
    "        iterations = iterations + 1\n",
    "        print(\"Iteration is: \",iterations)\n",
    "        print('\\n\\n\\n')\n",
    "        \n",
    "    rivers = data['x_train']\n",
    "    clusters = data['y_label']\n",
    "\n",
    "    clusters = np.array(clusters)\n",
    "    for cluster in range(0,len(np.unique(clusters))):\n",
    "        results = folder_path + experiment + \"/cluster_\"+str(cluster)+\"/\"\n",
    "        save_files(rivers[np.where(clusters == cluster)[0]], results, matplotlib_image)\n",
    "        \n",
    "        \n",
    "    # save model\n",
    "    path = results + 'model'\n",
    "    data['model'].save(path)\n",
    "    # read model\n",
    "    mode = model.load_model(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_training_epoches = 10 # for model.fit() function\n",
    "max_iter = 10 # for training, alternative is to check centroid for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 19:00:18.393236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,827,201\n",
      "Trainable params: 262,401\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ucl_model = select_model(1)['ucl_model']\n",
    "print(ucl_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### in EXP0_thresh70 results #########\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f31ce6b0c90>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "772/772 [==============================] - 106s 135ms/step\n",
      "Total number of rivers in cluster 0 :  (13404, 2048)\n",
      "Total number of rivers in cluster 1 :  (11278, 2048)\n",
      "After selection, there are 15288 selected from 24682\n",
      "in step4, x_train is  (15288, 64, 64, 3)\n",
      "in step4, y_label is  (15288,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f31cdc39390>\n",
      "Epoch 1/10\n",
      "153/153 [==============================] - 69s 428ms/step - loss: 0.1028 - accuracy: 0.6856\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 65s 426ms/step - loss: 0.0425 - accuracy: 0.6856\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 65s 427ms/step - loss: 0.0356 - accuracy: 0.6856\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 65s 427ms/step - loss: 0.0276 - accuracy: 0.6856\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 65s 428ms/step - loss: 0.0234 - accuracy: 0.6856\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 65s 427ms/step - loss: 0.0210 - accuracy: 0.6856\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 65s 426ms/step - loss: 0.0165 - accuracy: 0.6856\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 65s 428ms/step - loss: 0.0180 - accuracy: 0.6856\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 66s 428ms/step - loss: 0.0155 - accuracy: 0.6856\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 65s 426ms/step - loss: 0.0133 - accuracy: 0.6856\n",
      "Iteration is:  1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f31ce6b0c90>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "772/772 [==============================] - 104s 134ms/step\n",
      "Total number of rivers in cluster 0 :  (11278, 2048)\n",
      "Total number of rivers in cluster 1 :  (13404, 2048)\n",
      "After selection, there are 15288 selected from 24682\n",
      "in step4, x_train is  (15288, 64, 64, 3)\n",
      "in step4, y_label is  (15288,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f31cefdc790>\n",
      "Epoch 1/10\n",
      "153/153 [==============================] - 71s 443ms/step - loss: 1.2316 - accuracy: 0.3144\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 67s 440ms/step - loss: 0.0731 - accuracy: 0.3144\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 67s 441ms/step - loss: 0.0523 - accuracy: 0.3144\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 68s 441ms/step - loss: 0.0428 - accuracy: 0.3144\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 68s 441ms/step - loss: 0.0371 - accuracy: 0.3144\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 67s 440ms/step - loss: 0.0319 - accuracy: 0.3144\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 67s 440ms/step - loss: 0.0289 - accuracy: 0.3144\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 67s 440ms/step - loss: 0.0261 - accuracy: 0.3144\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 67s 440ms/step - loss: 0.0243 - accuracy: 0.3144\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 67s 441ms/step - loss: 0.0234 - accuracy: 0.3144\n",
      "Iteration is:  2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f31ce6b0c90>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "772/772 [==============================] - 104s 134ms/step\n",
      "Total number of rivers in cluster 0 :  (13404, 2048)\n",
      "Total number of rivers in cluster 1 :  (11278, 2048)\n",
      "After selection, there are 15288 selected from 24682\n",
      "in step4, x_train is  (15288, 64, 64, 3)\n",
      "in step4, y_label is  (15288,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f31cdf75e10>\n",
      "Epoch 1/10\n",
      "153/153 [==============================] - 69s 437ms/step - loss: 1.7998 - accuracy: 0.6856\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0226 - accuracy: 0.6856\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0198 - accuracy: 0.6856\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0157 - accuracy: 0.6856\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0142 - accuracy: 0.6856\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0147 - accuracy: 0.6856\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0121 - accuracy: 0.6856\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0106 - accuracy: 0.6856\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0084 - accuracy: 0.6856\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0077 - accuracy: 0.6856\n",
      "Iteration is:  3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f31ce6b0c90>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "772/772 [==============================] - 104s 135ms/step\n",
      "Total number of rivers in cluster 0 :  (13404, 2048)\n",
      "Total number of rivers in cluster 1 :  (11278, 2048)\n",
      "After selection, there are 15288 selected from 24682\n",
      "in step4, x_train is  (15288, 64, 64, 3)\n",
      "in step4, y_label is  (15288,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f31cd32ce50>\n",
      "Epoch 1/10\n",
      "153/153 [==============================] - 71s 444ms/step - loss: 0.0092 - accuracy: 0.6856\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 68s 442ms/step - loss: 0.0079 - accuracy: 0.6856\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 68s 442ms/step - loss: 0.0057 - accuracy: 0.6856\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 68s 442ms/step - loss: 0.0052 - accuracy: 0.6856\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 68s 441ms/step - loss: 0.0062 - accuracy: 0.6856\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 68s 442ms/step - loss: 0.0033 - accuracy: 0.6856\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 68s 443ms/step - loss: 0.0038 - accuracy: 0.6856\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 68s 442ms/step - loss: 0.0036 - accuracy: 0.6856\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 68s 442ms/step - loss: 0.0021 - accuracy: 0.6856\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 68s 442ms/step - loss: 0.0020 - accuracy: 0.6856\n",
      "Iteration is:  4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f31ce6b0c90>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "772/772 [==============================] - 104s 134ms/step\n",
      "Total number of rivers in cluster 0 :  (11278, 2048)\n",
      "Total number of rivers in cluster 1 :  (13404, 2048)\n",
      "After selection, there are 15288 selected from 24682\n",
      "in step4, x_train is  (15288, 64, 64, 3)\n",
      "in step4, y_label is  (15288,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f31cccb09d0>\n",
      "Epoch 1/10\n",
      "153/153 [==============================] - 69s 436ms/step - loss: 1.9550 - accuracy: 0.3144\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0280 - accuracy: 0.3144\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 67s 435ms/step - loss: 0.0249 - accuracy: 0.3144\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0225 - accuracy: 0.3144\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0213 - accuracy: 0.3144\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0203 - accuracy: 0.3144\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0196 - accuracy: 0.3144\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0188 - accuracy: 0.3144\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0182 - accuracy: 0.3144\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0174 - accuracy: 0.3144\n",
      "Iteration is:  5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f31ce6b0c90>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "772/772 [==============================] - 105s 135ms/step\n",
      "Total number of rivers in cluster 0 :  (13404, 2048)\n",
      "Total number of rivers in cluster 1 :  (11278, 2048)\n",
      "After selection, there are 15288 selected from 24682\n",
      "in step4, x_train is  (15288, 64, 64, 3)\n",
      "in step4, y_label is  (15288,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f31bf47ce10>\n",
      "Epoch 1/10\n",
      "153/153 [==============================] - 71s 443ms/step - loss: 1.4423 - accuracy: 0.6856\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 67s 438ms/step - loss: 0.0054 - accuracy: 0.6856\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 67s 438ms/step - loss: 0.0043 - accuracy: 0.6856\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 67s 437ms/step - loss: 0.0040 - accuracy: 0.6856\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 67s 437ms/step - loss: 0.0034 - accuracy: 0.6856\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 67s 437ms/step - loss: 0.0031 - accuracy: 0.6856\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0034 - accuracy: 0.6856\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 67s 437ms/step - loss: 0.0027 - accuracy: 0.6856\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0021 - accuracy: 0.6856\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 67s 436ms/step - loss: 0.0023 - accuracy: 0.6856\n",
      "Iteration is:  6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Layer type:  <keras.layers.reshaping.flatten.Flatten object at 0x7f31ce6b0c90>\n",
      "Layer details:  KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "772/772 [==============================] - 105s 135ms/step\n",
      "Total number of rivers in cluster 0 :  (13404, 2048)\n",
      "Total number of rivers in cluster 1 :  (11278, 2048)\n",
      "After selection, there are 15288 selected from 24682\n",
      "in step4, x_train is  (15288, 64, 64, 3)\n",
      "in step4, y_label is  (15288,)\n",
      "The training data with selected images and predicted label from kmeans is  <keras.preprocessing.image.NumpyArrayIterator object at 0x7f31bfa3a5d0>\n",
      "Epoch 1/10\n",
      " 60/153 [==========>...................] - ETA: 40s - loss: 0.0035 - accuracy: 0.6835"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "run_exp('EXP0_thresh70', 2, ucl_model, threshold, max_iter, X_train, max_training_epoches)\n",
    "\n",
    "# save the model \n",
    "torch.save(ucl_model, 'EXP0_thresh70.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test on the X_test dataset 317 rivers\n",
    "pred_classes70 = ucl_model.predict(X_test)\n",
    "\n",
    "# calculate accuracy / confusion matrix etc\n",
    "# 0.9997 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "MSI_Pytorch_1.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
